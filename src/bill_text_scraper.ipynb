{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting bill_text_scraper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile bill_text_scraper.py\n",
    "\n",
    "# this script pulls the necessary data from the vote_results jsonl files to create urls to scrape bill text\n",
    "# for example: https://www.congress.gov/bill/103rd-congress/house-bill/3400/text\n",
    "\n",
    "\n",
    "import codecs\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "def read_jsonl_file(path):\n",
    "    '''turn a jsonl file into an array of objects'''\n",
    "    arr = []\n",
    "    f = codecs.open(path, 'r', 'utf-8')\n",
    "    for line in f:\n",
    "        record = json.loads(line.rstrip('\\n|\\r'))\n",
    "        arr.append(record)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def write_json_file(obj, path):\n",
    "    '''Dump an object and write it out as json to a file'''\n",
    "    f = codecs.open(path, 'a', 'utf-8')\n",
    "    json_record = json.dumps(obj, ensure_ascii = False)\n",
    "    f.write(json_record + '\\n')\n",
    "    f.close\n",
    "    \n",
    "\n",
    "\n",
    "# create a dataframe of unique bills. Bill_ids will duplicate year over year.\n",
    "# exclude items that do not pretain to bill info\n",
    "print('----------------')\n",
    "print('... importing vote results data...')\n",
    "\n",
    "bill_list = []\n",
    "\n",
    "for filename in os.listdir('../data'):\n",
    "    if filename.startswith('vote_results'):\n",
    "#         print('\\tImporting {}'.format(filename))\n",
    "        file = read_jsonl_file('../data/{}'.format(filename))\n",
    "        \n",
    "        for line in file:\n",
    "            if (('QUORUM' not in line['issue']) & \n",
    "                ('JOURNAL' not in line['issue']) & \n",
    "                ('MOTION' not in line['issue']) & \n",
    "                ('ADJOURN' not in line['issue'])& \n",
    "                (line['issue'] != '')):\n",
    "                bill_list.append([line['year'], line['issue']])\n",
    "        \n",
    "        \n",
    "# convert bill_list to dataframe\n",
    "print('----------------')\n",
    "print('... creating dataframe of unique bills...')\n",
    "cols = ['year', 'issue']\n",
    "bills = pd.DataFrame(bill_list, columns = cols)\n",
    "\n",
    "\n",
    "# drop duplicates and nas\n",
    "bills.drop_duplicates(inplace = True)\n",
    "bills.dropna(inplace = True)\n",
    "\n",
    "\n",
    "# create congress ids for url crawl. One congress_id spans two years\n",
    "cong_id_list = []\n",
    "\n",
    "for y in range(101, 117):\n",
    "    if (y - 1)%10 == 0:\n",
    "        congress_id = '{}st-congress'.format(y)\n",
    "        cong_id_list.append(congress_id)\n",
    "\n",
    "    elif (y - 2)%10 == 0:\n",
    "        congress_id = '{}nd-congress'.format(y)\n",
    "        cong_id_list.append(congress_id)\n",
    "    \n",
    "    elif (y - 3)%10 == 0:\n",
    "        congress_id = '{}rd-congress'.format(y)\n",
    "        cong_id_list.append(congress_id)\n",
    "\n",
    "    else:\n",
    "        congress_id = '{}th-congress'.format(y)\n",
    "        cong_id_list.append(congress_id)\n",
    "\n",
    "years_odd = []\n",
    "for y in range(1989, 2019, 2):\n",
    "    years_odd.append(y)\n",
    "\n",
    "years_even = []\n",
    "for y in range(1990, 2020, 2):\n",
    "    years_even.append(y)\n",
    "\n",
    "    \n",
    "    \n",
    "# create dictionary of years (key) and congress_ids (value)\n",
    "print('----------------')\n",
    "print('... creating dictionaries of congress ids and available bill types... ')\n",
    "congress_ids = {}\n",
    "\n",
    "for y, i in zip(years_odd, cong_id_list):\n",
    "    congress_ids.update({y:i})\n",
    "\n",
    "for y, i in zip(years_even, cong_id_list):\n",
    "    congress_ids.update({y:i})\n",
    "\n",
    "    \n",
    "# append congress_ids to dataframe\n",
    "bills['congress_id'] = None\n",
    "for i in range(len(bills)):\n",
    "    bills.iloc[i, 2] = congress_ids[bills.iloc[i, 0]]\n",
    "\n",
    "    \n",
    "\n",
    "# create dictionary of bill_types to join to dataframe\n",
    "bill_types = {\n",
    "    'H R': 'house-bill',\n",
    "    'H RES': 'house-resolution', \n",
    "    'H J RES': 'house-joint-resolution',\n",
    "    'H CON RES': 'house-concurrent-resolution',\n",
    "    'S': 'senate-bill', \n",
    "    'S RES': 'senate-resolution', \n",
    "    'S J RES': 'senate-joint-resolution',\n",
    "    'S CON RES': 'senate-concurrent-resolution'    \n",
    "}\n",
    "\n",
    "\n",
    "# create columns for bill_type and bill_num\n",
    "print('----------------')\n",
    "print('... appending these to dataframe... ')\n",
    "bills['bill_type'] = None\n",
    "for i in range(len(bills)):\n",
    "    bills.iloc[i, 3] = bill_types[bills.iloc[i, 1].rsplit(' ', 1)[0]]\n",
    "    \n",
    "bills['bill_num'] = None\n",
    "for i in range(len(bills)):\n",
    "    bills.iloc[i, 4] = bills.iloc[i, 1].rsplit(' ', 1)[1]\n",
    "\n",
    "    \n",
    "\n",
    "# iterate through dataframe to build url and scrape bill text\n",
    "# example: https://www.congress.gov/bill/103rd-congress/house-bill/3400/text\n",
    "print('----------------')\n",
    "print('... finally... scraping bill texts... ')\n",
    "\n",
    "bills['bill_text'] = None\n",
    "\n",
    "root_url = 'https://www.congress.gov/bill'\n",
    "\n",
    "empty_row = {\n",
    "    'year': None, \n",
    "    'issue': None, \n",
    "    'congress_id': None, \n",
    "    'bill_type': None, \n",
    "    'bill_num': None, \n",
    "    'bill_text':None    \n",
    "}\n",
    "\n",
    "def to_jsonl_by_year(df, yr_list):\n",
    "    for y in yr_list:\n",
    "        print('Year: {}'.format(y))\n",
    "        bills = df[df['year'] == y]\n",
    "        for i in range(len(bills)):\n",
    "            issue = bills.iloc[i, 1]\n",
    "            c_id = bills.iloc[i, 2]\n",
    "            b_type = bills.iloc[i, 3]\n",
    "            b_num = bills.iloc[i, 4]\n",
    "\n",
    "            site_url = '{}/{}/{}/{}/text?format=txt'.format(root_url, c_id, b_type, b_num)\n",
    "#             print(site_url)\n",
    "\n",
    "            if i%50 == 0:\n",
    "                pct = 100 * i / len(bills)\n",
    "                print('\\t{:.2f} complete'.format(pct))\n",
    "\n",
    "            req = requests.get(site_url)\n",
    "            stat_code = req.status_code\n",
    "\n",
    "            # if error in getting url, print and log the error\n",
    "            if stat_code != 200:\n",
    "                print('_______________')\n",
    "                print('_______________')\n",
    "                print('\\t\\tError in retrieving bill text from {}'.format(site_url))\n",
    "                print('\\t\\tRequest Status Code: {}'.format(stat_code))\n",
    "                errored_line = {'url': site_url, 'error': stat_code}\n",
    "                write_json_file(errored_line, '../data/logs/bill_text_errors.jsonl')\n",
    "                print('Error logged in ../data/logs/bill_text_errors.jsonl')\n",
    "\n",
    "            if stat_code == 200:\n",
    "                req = requests.get(site_url)\n",
    "                soup = BeautifulSoup(req.content, 'lxml')\n",
    "                # print(soup.prettify())\n",
    "                \n",
    "                # if there is no text, print and log the error\n",
    "                if soup.find('pre') is None:\n",
    "                    print('_______________')\n",
    "                    print('_______________')\n",
    "                    print('\\t\\tError in retrieving bill text from {}'.format(site_url))\n",
    "                    print('\\t\\tNo text available for scraping.')\n",
    "                    errored_line = {'url': site_url, 'error': 'no text available'}\n",
    "                    write_json_file(errored_line, '../data/logs/bill_text_errors.jsonl')\n",
    "                    print('Error logged in ../data/logs/bill_text_errors.jsonl')\n",
    "                    \n",
    "    \n",
    "                # else scrape the text\n",
    "                else:\n",
    "                    bill_txt = soup.find('pre').text\n",
    "                    bill_txt = ' '.join(bill_txt.split())\n",
    "\n",
    "                    new_row = copy.copy(empty_row)\n",
    "                    new_row['year'] = str(bills.iloc[i, 0])\n",
    "                    new_row['issue'] = str(bills.iloc[i, 1])\n",
    "                    new_row['congress_id'] = str(bills.iloc[i, 2])\n",
    "                    new_row['bill_type'] = str(bills.iloc[i, 3])\n",
    "                    new_row['bill_num'] = str(bills.iloc[i, 4])\n",
    "                    new_row['bill_text'] = bill_txt\n",
    "\n",
    "                    outfile = '../data/bill_texts_{}.jsonl'.format(y)\n",
    "\n",
    "                    write_json_file(new_row, outfile)\n",
    "\n",
    "        i += 1\n",
    "        \n",
    "        if i == len(bills) - 1:\n",
    "            print('\\t100.00 complete')\n",
    "            print('\\tYear {} complete.'.format(y))\n",
    "\n",
    "# year_list = range(1990, 2019)\n",
    "# 1991 is 89% incomplete\n",
    "# year_list = range(1992, 2019)\n",
    "# 2007 is 90% complete\n",
    "# year_list = range(2008, 2019)\n",
    "# 2013 83% complete\n",
    "year_list = range(2013, 2019)\n",
    "\n",
    "# year_list = [1991, 2007]\n",
    "\n",
    "for y in year_list:\n",
    "    to_jsonl_by_year(bills, year_list)\n",
    "\n",
    "\n",
    "print('----------------')\n",
    "print('Script complete. Check results in ../data/bill_texts.jsonl. DATA SCIENCE!!!')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_url = 'https://www.congress.gov/bill/113rd-congress/house-bill/3273/text?format=txt'\n",
    "\n",
    "req = requests.get(site_url)\n",
    "soup = BeautifulSoup(req.content, 'lxml')\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_text = soup.find('pre')\n",
    "bill_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('pre') is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7d4c4bbfc473>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbill_txt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pre'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "bill_txt = soup.find('pre').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_txt = ' '.join(bill_txt.split())\n",
    "\n",
    "new_row = copy.copy(empty_row)\n",
    "new_row['year'] = str(bills.iloc[i, 0])\n",
    "new_row['issue'] = str(bills.iloc[i, 1])\n",
    "new_row['congress_id'] = str(bills.iloc[i, 2])\n",
    "new_row['bill_type'] = str(bills.iloc[i, 3])\n",
    "new_row['bill_num'] = str(bills.iloc[i, 4])\n",
    "new_row['bill_text'] = bill_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
