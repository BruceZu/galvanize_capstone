{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting get_new_bill_info.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile get_new_bill_info.py\n",
    "from pymongo import MongoClient\n",
    "import copy\n",
    "import os\n",
    "from datetime import date\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from random import randint\n",
    "from time import sleep\n",
    "import threading\n",
    "\n",
    "from my_tools import write_json_file\n",
    "\n",
    "\n",
    "def get_soup(url):\n",
    "    '''\n",
    "    ---------------------------------------\n",
    "    Get soup object from url to be parsed out in another function. If status code != 200, \n",
    "    prints out error message.\n",
    "    \n",
    "    ---------------------------------------\n",
    "    Parameters: url\n",
    "    \n",
    "    ---------------------------------------\n",
    "    Returns:    BeautifulSoup object\n",
    "    \n",
    "    ---------------------------------------\n",
    "    '''\n",
    "    # included sleep time to attempt human user mimicking\n",
    "    sleep_time = randint(0, 11)\n",
    "    sleep(sleep_time)\n",
    "    req = requests.get(url)\n",
    "    stat_code = req.status_code\n",
    "\n",
    "    if stat_code != 200:\n",
    "        print('_______________')\n",
    "        print('_______________')\n",
    "        print('Error requesting {}'.format(url))\n",
    "        print('Request Status Code: {}'.format(stat_code))\n",
    "\n",
    "    if stat_code == 200:            \n",
    "        print('_______________')\n",
    "        print('_______________')\n",
    "        print('\\tRetrieving soup from {}'.format(url))\n",
    "        soup = BeautifulSoup(req.content, 'lxml')\n",
    "        \n",
    "        return soup\n",
    "    \n",
    "\n",
    "    \n",
    "def soup_details_to_list(soup):\n",
    "    '''\n",
    "    ---------------------------------------\n",
    "    Parses out the details from the soup object and inserts the details into list. Each \n",
    "    item in the list will be compared to the data that already exists in Mongo.\n",
    "    \n",
    "    ---------------------------------------\n",
    "    Parameters: soup - a soup object with table within 'ol' class\n",
    "                collection - collection name of Mongo database\n",
    "                \n",
    "    ---------------------------------------\n",
    "    Returns:    list of bill details to compare to what is already in Mongo\n",
    "    \n",
    "    ---------------------------------------\n",
    "    '''\n",
    "    # initialize empty list to temporarily store data.\n",
    "    # each item will be checked against Mongo data to see if anything has changed since the last load.\n",
    "    all_rows = []\n",
    "    \n",
    "    # initialize empty row to populate data\n",
    "    empty_row = {'leg_id': None, \n",
    "                'leg_type': None,\n",
    "                'leg_url': None,\n",
    "                'intro_date': None,\n",
    "                'congress_id': None,\n",
    "                'desc': None,\n",
    "                'sponsor': None, \n",
    "                'sponsor_party': None, \n",
    "                'sponsor_state': None,\n",
    "                'sponsor_district': None,  #senators don't have districts\n",
    "                'num_of_cosponsors': None,\n",
    "                'cosponsors_url': None,\n",
    "                'cosponsors': None,        #requires navigation to another url and extracting names from table\n",
    "                'num_of_amendments': None,  #requires navigation to another url\n",
    "                'committee': None, \n",
    "                'bill_status': None,\n",
    "                'body': None               #requires navigation to another url\n",
    "                }\n",
    "\n",
    "\n",
    "    # table of bills are in ol class\n",
    "    div = soup.find('div', {'class':'search-column-main'})\n",
    "    table = div.find('ol')\n",
    "\n",
    "    # iterate though each li class expanded to get rows\n",
    "    rows = table.find_all('li', {'class':'expanded'})\n",
    "   \n",
    "    for row in rows:\n",
    "        new_row = copy.copy(empty_row)\n",
    "        \n",
    "#         # debugging\n",
    "#         columns = row.find_all('a')\n",
    "#         if columns[0].text.strip() != '':\n",
    "#             print(columns[0].text.strip().replace('.', ' '))\n",
    "        \n",
    "        # parse items within 'span' tag\n",
    "        columns = row.find_all('span')\n",
    "        if len(columns) > 3:\n",
    "            # we only want bills and joint resolutions\n",
    "            legislation_type = columns[0].text.strip()\n",
    "\n",
    "            if (legislation_type == 'BILL') |  (legislation_type == 'JOINT RESOLUTION') | (legislation_type == 'LAW'):\n",
    "                if columns[0].text != '':\n",
    "                    new_row['leg_type'] = legislation_type\n",
    "                if columns[1].text.strip().split()[2] != '':\n",
    "                    new_row['congress_id'] = columns[1].text.strip().split()[2][:3]\n",
    "                if columns[2].text != '':\n",
    "                    new_row['desc'] = columns[2].text\n",
    "                if ('Committee' in columns[4].text):\n",
    "                    new_row['committee'] = columns[4].text.strip()[12:]\n",
    "\n",
    "                dt = columns[3].text.strip().split()\n",
    "                if '(Introduced' in dt:\n",
    "                    new_row['intro_date'] = dt[dt.index('(Introduced') + 1][:-1]\n",
    "\n",
    "\n",
    "                # bill_status is within 'p' tag\n",
    "                columns = row.find_all('p')\n",
    "                if columns[0].text.strip()[25:] != '':\n",
    "                    new_row['bill_status'] = columns[0].text.strip()[25:]\n",
    "\n",
    "\n",
    "                # parse info within 'a' tag\n",
    "                columns = row.find_all('a')\n",
    "                if columns[0].text.strip() != '':\n",
    "                    new_row['leg_id'] = columns[0].text.strip().replace('.', ' ')\n",
    "\n",
    "                # also within 'a' tag, reserved bill numbers will not have the information below\n",
    "                if (len(columns) > 2):    \n",
    "                    if columns[0]['href'].strip() != '':\n",
    "                        new_row['leg_url'] = columns[0]['href'].strip()\n",
    "                    if columns[2].text.strip() != '':\n",
    "                        new_row['num_of_cosponsors'] = columns[2].text.strip()\n",
    "                        if new_row['num_of_cosponsors'] != '0':\n",
    "                            new_row['cosponsors_url'] = columns[2]['href']\n",
    "\n",
    "                # party, state, and district (for house reps) need to be stripped out of sponsor info\n",
    "                    for c in range(len(columns)):\n",
    "                        if '[' in columns[c].text.strip():\n",
    "                            rep = columns[c].text.strip()\n",
    "                            new_row['sponsor'] = rep.rsplit('[', 1)[0][:-1][5:]\n",
    "                            party_dist = rep.rsplit('[', 1)[1][: -1]\n",
    "                            party_dist_split = party_dist.split('-')\n",
    "                            new_row['sponsor_state'] = party_dist_split[1]\n",
    "                            new_row['sponsor_party'] = party_dist_split[0]\n",
    "                            if len(party_dist_split) == 3:\n",
    "                                new_row['sponsor_district'] = party_dist_split[2]\n",
    "\n",
    "                all_rows.append(new_row)\n",
    "            \n",
    "    return all_rows\n",
    "\n",
    "\n",
    "\n",
    "def mongo_check(leg_id, cong_id, collection):\n",
    "    '''\n",
    "    ---------------------------------------\n",
    "    Checks to see if a record from web scrape is in Mongo by querying the leg_id and\n",
    "    cong_id. Returns True if present, else returns False.\n",
    "    \n",
    "    ---------------------------------------\n",
    "    Parameters: leg_id - the bill identifier\n",
    "                cong_id - the congress id the bill was introduced in\n",
    "                collection - Mongo collection\n",
    "                \n",
    "    ---------------------------------------\n",
    "    Returns:    boolean - False if record is not present in Mongo, else True\n",
    "    \n",
    "    ---------------------------------------\n",
    "    '''\n",
    "    mongo_record = collection.find_one({'leg_id': leg_id, 'congress_id': cong_id})\n",
    "    if mongo_record is None: \n",
    "        print('Congress ID {}, Bill {} not in Mongo'.format(cong_id, leg_id))\n",
    "        return False\n",
    "    else: \n",
    "        return True\n",
    "\n",
    "    \n",
    "\n",
    "def update_mongo_value(leg_id, cong_id, key_to_update, new_value, collection):  \n",
    "    '''\n",
    "    ---------------------------------------\n",
    "    Updates the value for a single key in a mongo record specified by leg_id and\n",
    "    cong_id (congress_id) from db.collection with new_value.\n",
    "    \n",
    "    ---------------------------------------\n",
    "    Parameters: leg_id - value to filter on for key leg_id\n",
    "                cong_id - value to filter on for key congress_id\n",
    "                key_to_update - key from document that needs to be updated\n",
    "                new_value - new value to be inserted into mongo document\n",
    "                collection - the name of the mongo collection\n",
    "                \n",
    "    ---------------------------------------\n",
    "    Returns:    None\n",
    "    \n",
    "    ---------------------------------------\n",
    "    '''\n",
    "    collection.update_one({'leg_id': leg_id, 'congress_id': cong_id}, {'$set': {key_to_update: new_value}})\n",
    "\n",
    "\n",
    "    \n",
    "def update_mongo_with_list_values(bill_list, collection):\n",
    "    '''\n",
    "    ---------------------------------------\n",
    "    Compares each item in bill_list (scraped data) to documents in Mongo collection. \n",
    "    \n",
    "    If the item is not in Mongo, it inserts it.\n",
    "\n",
    "    If the item is in Mongo collection, it updates values if they do not match by \n",
    "    calling function update_mongo_value.\n",
    "    \n",
    "    ---------------------------------------\n",
    "    Parameters: bill_list - list of bills created from web scrape (soup_details_to_list)\n",
    "                collection - Mongo collection to query and update, if needed.\n",
    "                 \n",
    "    ---------------------------------------\n",
    "    Returns:    None\n",
    "    \n",
    "    ---------------------------------------\n",
    "    '''\n",
    "    keys_to_check = ['leg_type', 'desc', 'num_of_cosponsors', 'committee', 'bill_status']\n",
    "\n",
    "    for i in range(len(bill_list)): \n",
    "\n",
    "        list_record = bill_list[i]\n",
    "\n",
    "        leg_id = list_record['leg_id']\n",
    "        cong_id = list_record['congress_id']\n",
    "        \n",
    "        # check to see if list_record is in Mongo collection and update values\n",
    "        mongo_document = collection.find_one({'leg_id': leg_id, 'congress_id': cong_id})\n",
    "\n",
    "        if mongo_check(leg_id, cong_id, collection):\n",
    "            for k in keys_to_check:\n",
    "                if list_record[k] != mongo_document[k]:\n",
    "                    print('\\tLogging and updating {} {}... \\n\\t\\t...from {} \\n\\t\\t...to {}'.format(leg_id, k, mongo_document[k], list_record[k]))\n",
    "\n",
    "                    line_to_log = {'congress_id': cong_id, 'leg_id': leg_id, k: {'old_value': mongo_document[k], 'new_value': list_record[k], 'date': str(date.today().isoformat())}}\n",
    "                    write_json_file(line_to_log, '/home/ubuntu/galvanize_capstone/data/logs/mongo_updates.jsonl')\n",
    "                    update_mongo_value(leg_id, cong_id, k, list_record[k], collection)\n",
    "        \n",
    "        # if list_record not in Mongo, insert it\n",
    "        else:\n",
    "            print('\\tInserting new bill {}'.format(leg_id))\n",
    "            collection.insert_one(list_record)\n",
    "                \n",
    "\n",
    "\n",
    "def min_cong_id_in_soup(soup):\n",
    "    '''\n",
    "    ---------------------------------------\n",
    "    Returns the min of congress_id scraped from a soup object. Used to limit web scraping.\n",
    "    ---------------------------------------\n",
    "    '''\n",
    "    cong_ids = []\n",
    "\n",
    "    # table of bills are in ol class\n",
    "    div = soup.find('div', {'class':'search-column-main'})\n",
    "    table = div.find('ol')\n",
    "\n",
    "    # iterate though each li class expanded to get rows\n",
    "    rows = table.find_all('li', {'class':'expanded'})\n",
    "   \n",
    "    for row in rows:\n",
    "        # parse items within 'span' tag\n",
    "        columns = row.find_all('span')\n",
    "\n",
    "        if columns[1].text.strip().split()[2] != '':\n",
    "            cong_id = columns[1].text.strip().split()[-3][:3]\n",
    "\n",
    "            cong_ids.append(int(cong_id))\n",
    "\n",
    "    return min(cong_ids)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('*****************')\n",
    "    print('This script is scraping to update bill info in Mongo.')\n",
    "    \n",
    "    log_path = '/home/ubuntu/galvanize_capstone/data/logs/mongo_updates.jsonl'\n",
    "    print('Results of this update will be logged in {}'.format(log_path))\n",
    "    \n",
    "    # initialize Mongo client\n",
    "    client = MongoClient()\n",
    "    db = client.bills\n",
    "    bill_info = db.bill_info\n",
    "\n",
    "#     # reset log. Decided to persist this log to track movement\n",
    "#     if os.path.exists(log_path):\n",
    "#         os.remove(log_path)\n",
    "\n",
    "    # 110th Congress ends at page 444, but break will limit scraping\n",
    "    page_range = range(1, 500)\n",
    "    \n",
    "    min_cong_id = 116\n",
    "\n",
    "    url_root = 'https://www.congress.gov/search?q=%7B%22source%22%3A%22legislation%22%7D&pageSize=250&page='\n",
    "\n",
    "    for p in page_range:\n",
    "        # update Mongo with site contents where necessary\n",
    "        site_url = '{}{}'.format(url_root, p)\n",
    "        soup = get_soup(site_url)\n",
    "        bill_list = soup_details_to_list(soup)\n",
    "        update_mongo_with_list_values(bill_list, bill_info)\n",
    "\n",
    "        # break out of loop if the min congress id limit has been reached\n",
    "        min_cong_id_on_page = min_cong_id_in_soup(soup)\n",
    "        if min_cong_id_on_page < min_cong_id:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________\n",
      "_______________\n",
      "\tRetrieving soup from https://www.congress.gov/search?q=%7B%22source%22%3A%22legislation%22%7D&pageSize=250&page=30\n"
     ]
    }
   ],
   "source": [
    "# exploration\n",
    "from pymongo import MongoClient\n",
    "import copy\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "url_root = 'https://www.congress.gov/search?q=%7B%22source%22%3A%22legislation%22%7D&pageSize=250&page='\n",
    "\n",
    "p = 30\n",
    "\n",
    "# update Mongo with site contents where necessary\n",
    "site_url = '{}{}'.format(url_root, p)\n",
    "soup = get_soup(site_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-01-06'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date.today().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_list = soup_details_to_list(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_mongo_with_list_values(bill_list, bill_info)\n",
    "\n",
    "# break out of loop if the min congress id limit has been reached\n",
    "min_cong_id_on_page = min_cong_id_in_soup(soup)\n",
    "if min_cong_id_on_page < min_cong_id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________\n",
      "_______________\n",
      "\tRetrieving soup from https://www.congress.gov/search?q=%7B%22source%22%3A%22legislation%22%7D&pageSize=250&page=10\n",
      "\tLogging and updating H R 5121 num_of_cosponsors... \n",
      "\t\t...from 46 \n",
      "\t\t...to 47\n",
      "\tLogging and updating H R 5087 num_of_cosponsors... \n",
      "\t\t...from 176 \n",
      "\t\t...to 178\n",
      "\tLogging and updating H R 5075 leg_type... \n",
      "\t\t...from BILL \n",
      "\t\t...to LAW\n",
      "\tLogging and updating H R 5075 bill_status... \n",
      "\t\t...from Passed House \n",
      "\t\t...to Became Law\n",
      "\tLogging and updating H R 5060 num_of_cosponsors... \n",
      "\t\t...from 25 \n",
      "\t\t...to 26\n",
      "\tLogging and updating H R 5058 num_of_cosponsors... \n",
      "\t\t...from 33 \n",
      "\t\t...to 34\n",
      "\tLogging and updating H R 5034 num_of_cosponsors... \n",
      "\t\t...from 141 \n",
      "\t\t...to 142\n",
      "\tLogging and updating H R 5011 num_of_cosponsors... \n",
      "\t\t...from 124 \n",
      "\t\t...to 126\n",
      "\tLogging and updating H R 5008 num_of_cosponsors... \n",
      "\t\t...from 2 \n",
      "\t\t...to 4\n",
      "\tLogging and updating H R 4969 bill_status... \n",
      "\t\t...from Passed House \n",
      "\t\t...to Passed Senate\n",
      "\tLogging and updating H R 4960 leg_type... \n",
      "\t\t...from BILL \n",
      "\t\t...to LAW\n",
      "\tLogging and updating H R 4960 bill_status... \n",
      "\t\t...from To President \n",
      "\t\t...to Became Law\n",
      "\tLogging and updating H R 4946 leg_type... \n",
      "\t\t...from BILL \n",
      "\t\t...to LAW\n",
      "\tLogging and updating H R 4946 bill_status... \n",
      "\t\t...from To President \n",
      "\t\t...to Became Law\n",
      "\tLogging and updating H R 4941 num_of_cosponsors... \n",
      "\t\t...from 17 \n",
      "\t\t...to 18\n",
      "\tLogging and updating H R 4913 leg_type... \n",
      "\t\t...from BILL \n",
      "\t\t...to LAW\n",
      "\tLogging and updating H R 4913 bill_status... \n",
      "\t\t...from To President \n",
      "\t\t...to Became Law\n",
      "\tLogging and updating H R 4912 num_of_cosponsors... \n",
      "\t\t...from 28 \n",
      "\t\t...to 29\n"
     ]
    }
   ],
   "source": [
    "page = 10\n",
    "\n",
    "\n",
    "url_root = 'https://www.congress.gov/search?q=%7B%22source%22%3A%22legislation%22%7D&pageSize=250&page='\n",
    "\n",
    "site_url = '{}{}'.format(url_root, page)\n",
    "\n",
    "soup = get_soup(site_url)\n",
    "\n",
    "bill_list = soup_details_to_list(soup)\n",
    "\n",
    "update_mongo_with_list_values(bill_list, bill_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_record = bill_details.find_one({'leg_id': leg_id, 'congress_id': cong_id})\n",
    "mongo_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
