{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile random_forest_model.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import pprint\n",
    "import string\n",
    "import re\n",
    "import datetime\n",
    "import copy\n",
    "\n",
    "from my_tools import get_bill_data\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as scs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB#, ComplementNB unreleased as of 12/14\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_bill_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passed_df = data[data['labels'] == 1]\n",
    "\n",
    "fig = plt.figure(figsize = (30, 12))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title('Number of Bills Introduced (red) and Passed (green) vs. Time', fontdict={'fontsize': 24})\n",
    "ax.hist(data['intro_date'], bins = 500, alpha = .3, color = 'r')\n",
    "ax.hist(passed_df['intro_date'], bins = 1000, color = 'g')\n",
    "ax.set_ylim(0, 400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf1 = data[data['num_of_amendments'] == 18]\n",
    "# adf2 = data[data['num_of_amendments'] == 2]\n",
    "# adf3 = data[data['num_of_amendments'] == 3]\n",
    "# adf4 = data[data['num_of_amendments'] == 4]\n",
    "# adf5 = data[data['num_of_amendments'] == 5]\n",
    "# adf6 = data[data['num_of_amendments'] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(adf1.labels.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_range = []\n",
    "i_equal = []\n",
    "i_below = []\n",
    "i_above = []\n",
    "\n",
    "for i in range(1, 101):\n",
    "    df = data[data['num_of_amendments'] == i]\n",
    "    dfb = data[data['num_of_amendments'] < i]\n",
    "    dfa = data[data['num_of_amendments'] > i]\n",
    "    if len(df.labels.value_counts()) == 2:\n",
    "    #     print(df.labels.value_counts())\n",
    "        at_value = 100 * df.labels.value_counts()[1] / len(df)\n",
    "        below_value = 100 * dfb.labels.value_counts()[1] / len(df)\n",
    "        above_value = 100 * dfa.labels.value_counts()[1] / len(df)\n",
    "        \n",
    "        i_range.append(i)\n",
    "        i_equal.append(at_value)\n",
    "        i_below.append(below_value)\n",
    "        i_above.append(above_value)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(i_range), len(i_equal), len(i_below), len(i_above))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (30, 12))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title('Number of Bills Introduced (red) and Passed (green) vs. Time', fontdict={'fontsize': 24})\n",
    "ax.plot(i_range, i_equal)\n",
    "ax.plot(i_range, i_below)\n",
    "ax.plot(i_range, i_above)\n",
    "\n",
    "# ax.hist(data['intro_date'], bins = 500, alpha = .3, color = 'r')\n",
    "# ax.hist(passed_df['intro_date'], bins = 1000, color = 'g')\n",
    "# ax.set_ylim(0, 400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First iteration of Random Forest showed that congress_id 115th is a top feature when measured using \n",
    "# average Gini importance. Of course it is... nothing was labeled with 0 since every bill that hasn't\n",
    "# become law is still 'in progress'. The predictions that users will be looking for will always be from the \n",
    "# most recent Congress. Therefore, remove congress_id...\n",
    "\n",
    "# Second iteration removes num_of_cosponsors and bill_char_counts...\n",
    "data_features = data.loc[:, [\n",
    "                            'sponsor',\n",
    "                            'num_of_cosponsors', \n",
    "                            'sponsor_party', \n",
    "                            'sponsor_state', \n",
    "                            'num_of_amendments',\n",
    "#                             'bill_char_counts', \n",
    "                            'char_count_bucket',\n",
    "                            'intro_month', \n",
    "                            'session', \n",
    "                            'labels'\n",
    "                            ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies for intro_month, sponsor_party, sponsor_state, session\n",
    "data_dumm = pd.get_dummies(data_features, columns = [\n",
    "                                            'intro_month',\n",
    "                                            'sponsor',\n",
    "                                            'sponsor_party', \n",
    "                                            'sponsor_state', \n",
    "                                            'session', \n",
    "                                            'char_count_bucket'\n",
    "                                            ], \n",
    "                           drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dumm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_it(x, y_list, name, labels):\n",
    "    x = x\n",
    "    fig = plt.figure(figsize = (16, 8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(name, fontdict = {'fontsize': 20})\n",
    "    for y in y_list:\n",
    "        plt.plot(x, y)\n",
    "    plt.legend(labels)\n",
    "\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_dumm.pop('labels').values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_dumm, y, \n",
    "                                                    stratify = y, \n",
    "                                                    random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through several n_estimators to find best \n",
    "n_list = range(600, 640, 2)\n",
    "r_list = []\n",
    "\n",
    "print('----------------')\n",
    "print('Iterating through several n_estimators for a Random Forest model...')\n",
    "\n",
    "for n in n_list:\n",
    "    print('--> n = {}'.format(n))\n",
    "    rf = RandomForestClassifier(n_estimators=n, \n",
    "                                max_features = 'auto', \n",
    "                                random_state = 123, \n",
    "                                n_jobs = -1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    rf_y_pred = rf.predict(X_test)\n",
    "    r_list.append(recall_score(y_test, rf_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show graph of scores vs. number of max_features \n",
    "x = np.arange(600, 640, 2)\n",
    "plot_list = [r_list]\n",
    "graph_name = 'Random Forest n_estimators vs. Recall Score'\n",
    "labels = ['recall score']\n",
    "\n",
    "plot_it(x, plot_list, graph_name, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(r_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=610, \n",
    "                            max_features = 'auto', \n",
    "                            random_state = 123, \n",
    "                            n_jobs = -1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_pred = rf.predict(X_test)\n",
    "\n",
    "print('----------------------')\n",
    "print('----------------------')\n",
    "print('Random Forest Classification')\n",
    "print('----------------------')\n",
    "print('Accuracy score:  {:.2f}'.format(accuracy_score(y_test, rf_y_pred)))\n",
    "print('Precision score: {:.2f}'.format(precision_score(y_test, rf_y_pred)))\n",
    "print('Recall score:    {:.2f}'.format(recall_score(y_test, rf_y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importance\n",
    "feat_scores = pd.Series(rf.feature_importances_,\n",
    "                           index=X_train.columns)\n",
    "feat_scores = feat_scores.sort_values()[::-1][:20][::-1]\n",
    "ax = feat_scores.plot(kind='barh', \n",
    "                      figsize=(10,8),\n",
    "                      color='b')\n",
    "ax.set_title('Average Gini Importance (Top 20 features)')\n",
    "ax.set_xlabel('Average contribution to information gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
