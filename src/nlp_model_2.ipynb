{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from my_tools import get_bill_data, process_corpus\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB#, ComplementNB unreleased as of 12/14\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client.bills\n",
    "bill_info = db.bill_info\n",
    "\n",
    "# monitoring progress of data into Mongo\n",
    "print('Number of documents in database:\\t{}'.format(bill_info.count_documents({})))\n",
    "\n",
    "records_with_text = bill_info.count_documents({'body': {'$regex': '(.+)'}})\n",
    "print('Documents with bill text:\\t\\t{}'.format(records_with_text))\n",
    "\n",
    "records_wo_text = bill_info.count_documents({'body': None})\n",
    "print('Documents without bill text:\\t\\t{}'.format(records_wo_text))\n",
    "\n",
    "records_with_amend_count = bill_info.count_documents({'num_of_amendments': {'$regex': '(.+)'}})\n",
    "print('Documents with amend count:\\t\\t{}'.format(records_with_amend_count))\n",
    "\n",
    "records_wo_amend_count = bill_info.count_documents({'num_of_amendments': None})\n",
    "print('Documents without amend count:\\t\\t{}'.format(records_wo_amend_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Amendment Counts')\n",
    "print('cong_id\\tWith\\tWithout')\n",
    "\n",
    "for i in range(110, 116):\n",
    "    cong_id = str(i)\n",
    "    with_amend = bill_info.count_documents({'congress_id': cong_id, 'num_of_amendments': {'$regex': '(.+)'}})\n",
    "    wo_amend = bill_info.count_documents({'congress_id': cong_id, 'num_of_amendments': None})\n",
    "    print('{}: \\t{} \\t{}'.format(cong_id, with_amend, wo_amend))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = get_bill_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = process_corpus(data, 'body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stratified train-test split\n",
    "print('-------------------')\n",
    "print('Doing train-test split...')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-------------------')\n",
    "print('Training...')\n",
    "tfvect = TfidfVectorizer(ngram_range=(1, 4))\n",
    "X_train_vec = tfvect.fit_transform(X_train)\n",
    "X_test_vec = tfvect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tfvect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs = -1)\n",
    "rf.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_pred = rf.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recall_score(y_test, rf_y_pred))\n",
    "print(precision_score(y_test, rf_y_pred))\n",
    "print(accuracy_score(y_test, rf_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, rf_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importance\n",
    "feat_scores = pd.Series(rf.feature_importances_,\n",
    "                           index=vocab)\n",
    "feat_scores = feat_scores.sort_values()[::-1][:20][::-1]\n",
    "ax = feat_scores.plot(kind='barh', \n",
    "                      figsize=(10,8),\n",
    "                      color='b')\n",
    "ax.set_title('Average Gini Importance (Top 20 features)')\n",
    "ax.set_xlabel('Average contribution to information gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
