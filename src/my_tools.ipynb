{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting my_tools.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_tools.py\n",
    "import json\n",
    "import codecs\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import datetime\n",
    "\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize, RegexpTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet  import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams, skipgrams\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_jsonl_file(path):\n",
    "    '''turn a jsonl file (carriage returns per record) into an array of objects'''\n",
    "    arr = []\n",
    "    f = codecs.open(path, 'r', 'utf-8')\n",
    "    for line in f:\n",
    "        record = json.loads(line.rstrip('\\n|\\r'))\n",
    "        arr.append(record)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def read_json_file(path):\n",
    "    '''Turn a normal json file (no carriage returns per record) into an object'''\n",
    "    text = codecs.open(path, 'r', 'utf-8').read()\n",
    "    return json.loads(text)\n",
    "\n",
    "\n",
    "def write_jsonl_file(list_of_objects, path):\n",
    "    '''Dump a list of objects out as a jsonl file'''\n",
    "    f = codecs.open(path, 'w', 'utf-8')\n",
    "    for row in list_of_objects:\n",
    "        json_record = json.dumps(row, ensure_ascii = False)\n",
    "        f.write(json_record + '\\n')\n",
    "    f.close()\n",
    "\n",
    "    \n",
    "def write_json_file(obj, path):\n",
    "    '''Dump an object and write it out as json to a file'''\n",
    "    f = codecs.open(path, 'a', 'utf-8')\n",
    "    json_record = json.dumps(obj, ensure_ascii = False)\n",
    "    f.write(json_record + '\\n')\n",
    "    f.close\n",
    "    \n",
    "    \n",
    "def get_bill_data():\n",
    "    '''\n",
    "    Query data from mongo db bills.bill_details and return a pandas dataframe.\n",
    "    \n",
    "    The data relevant to this project is currently set up to be limited to the \n",
    "    110th Congress forward.\n",
    "    --------------------\n",
    "    Parameters: None.\n",
    "    --------------------    \n",
    "    Returns: pandas dataframe with relevant data and corresponding labels.\n",
    "                \n",
    "    '''\n",
    "    # connect to mongodb\n",
    "    client = MongoClient() # defaults to localhost\n",
    "    db = client.bills\n",
    "    bill_details = db.bill_details\n",
    "    \n",
    "    # get mongoo data and convert mongo query resuls to dataframe\n",
    "    # need to execute query (.find) everytime i refer to it?\n",
    "    records_with_text = bill_details.find({'body': {'$regex': 'e'}})\n",
    "    data = pd.DataFrame(list(records_with_text))\n",
    "\n",
    "    # filter out simple resolutions, concurrent resolutions, and amendments (for prelim model)\n",
    "    data = data[(data['leg_type'] != 'RESOLUTION') & (data['leg_type'] != 'CONCURRENT RESOLUTION') & (data['leg_type'] != 'AMENDMENT')]\n",
    "    \n",
    "    # create column for character counts of the bill text\n",
    "    bill_lengths = list(map(lambda x: len(x), data['body']))\n",
    "    data['bill_char_counts'] = bill_lengths\n",
    "    \n",
    "    # convert date column to type datetime\n",
    "    data['intro_date'] = data['intro_date'].apply(lambda x: datetime.datetime.strptime(x[:10], '%m/%d/%Y'))\n",
    "\n",
    "    # strip out month from intro date\n",
    "    data['intro_month'] = data['intro_date'].apply(lambda x: x.month)\n",
    "    \n",
    "    # get session from year (odd years are Session 1, even years are Session 2)\n",
    "    data['session'] = data['congress_id'].apply(lambda x: 2 if int(x[:3])%2 == 0 else 1)\n",
    "    \n",
    "    # correction for mislabeled sponsor_state and sponsor_party\n",
    "    state = copy.copy(data['sponsor_state'])\n",
    "    party = copy.copy(data['sponsor_party'])\n",
    "    data['sponsor_state'] = party\n",
    "    data['sponsor_party'] = state\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     print('------------------')\n",
    "#     print('Creating column \\'labels\\'...')\n",
    "    \n",
    "    # break up dataframe into those that became law and others (did not or still pending)\n",
    "    became_law = data[(data['bill_status'] == 'Became Law') | (data['bill_status'] == 'Became Private Law')]\n",
    "    others = data[(data['bill_status'] != 'Became Law') & (data['bill_status'] != 'Became Private Law')]\n",
    "\n",
    "    became_law.loc[:, 'labels'] = 1\n",
    "\n",
    "\n",
    "\n",
    "    # break up others into current congress and previous ones. Anything that hasn't been signed into law\n",
    "    # before current session is dead. Currently, all bills vetoed by the president come from previous congresses\n",
    "    current_cong = others[others['congress_id'] == '115th']\n",
    "    prev_cong = others[others['congress_id'] != '115th']\n",
    "\n",
    "    prev_cong.loc[:, 'labels'] = 0\n",
    "\n",
    "\n",
    "\n",
    "    # let's label To President and Resolving Differences with 1. Everything else is on the floor\n",
    "    to_pres = current_cong[(current_cong['bill_status'] == 'To President') | (current_cong['bill_status'] == 'Resolving Differences')]\n",
    "    on_floor = current_cong[(current_cong['bill_status'] != 'To President') & (current_cong['bill_status'] != 'Resolving Differences')]\n",
    "\n",
    "    to_pres.loc[:, 'labels'] = 1\n",
    "\n",
    "\n",
    "\n",
    "    # break up bills on the floor to failed (0) and not failed\n",
    "    failed = on_floor[on_floor['bill_status'].str.startswith('Failed')]\n",
    "    not_failed = on_floor[~on_floor['bill_status'].str.startswith('Failed')]\n",
    "\n",
    "    failed.loc[:, 'labels'] = 0\n",
    "\n",
    "\n",
    "\n",
    "    # bills that haven't failed yet have either been just introduced or on their way\n",
    "    # label introduced with 'in_progress'. These will not be a part of our model.\n",
    "    introduced = not_failed[not_failed['bill_status'] == 'Introduced']\n",
    "    beyond_intro = not_failed[not_failed['bill_status'] != 'Introduced']\n",
    "\n",
    "    introduced.loc[:, 'labels'] = 'in_progress'\n",
    "\n",
    "\n",
    "\n",
    "    # there are bills that started in one chamber and have already passed the other. We'll label\n",
    "    # these with a 1\n",
    "    passed_opp_chamber = beyond_intro[(beyond_intro['bill_status'] == 'Passed House') & (beyond_intro['leg_id'].str.startswith('S')) | \n",
    "                              (beyond_intro['bill_status'] == 'Passed Senate') & (beyond_intro['leg_id'].str.startswith('H'))]\n",
    "\n",
    "    passed_opp_chamber.loc[:, 'labels'] = 1\n",
    "\n",
    "\n",
    "\n",
    "    # bills that are still in the chamber they were introduced in are 'in_progress'\n",
    "    in_orig_chamber = beyond_intro[(beyond_intro['bill_status'] == 'Passed House') & (beyond_intro['leg_id'].str.startswith('H')) | \n",
    "                              (beyond_intro['bill_status'] == 'Passed Senate') & (beyond_intro['leg_id'].str.startswith('S'))]    \n",
    "\n",
    "    in_orig_chamber.loc[:, 'labels'] = 'in_progress'\n",
    "\n",
    "\n",
    "\n",
    "    # bring all the information back together\n",
    "    data_l = pd.concat([became_law, prev_cong, to_pres, failed, introduced, passed_opp_chamber, in_orig_chamber])\n",
    "\n",
    "    # filter out those that are still in progress\n",
    "    df = data_l[data_l['labels'] != 'in_progress']\n",
    "\n",
    "    # filter for most recent congress_ids\n",
    "    small_df = df[(df['congress_id'] == '115th') | \n",
    "              (df['congress_id'] == '114th') | \n",
    "              (df['congress_id'] == '113th')| \n",
    "              (df['congress_id'] == '112th')| \n",
    "              (df['congress_id'] == '111th')| \n",
    "              (df['congress_id'] == '110th')]\n",
    "    \n",
    "    print('------------------')\n",
    "    print('------------------')\n",
    "    print('Data is from the 110th Congress (2007) to present')\n",
    "    print('------------------')\n",
    "    \n",
    "    return small_df.reset_index(inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "def process_corpus(df, corpus_col_name, labels_col_name):\n",
    "    '''\n",
    "    Processes the text in df[corpus_col_name] to return a corpus (list) and the series of \n",
    "    corresponding labels in df[label_col_name].\n",
    "    \n",
    "    The intent of this function is to feed the output into a stratified train-test split.\n",
    "    -------------------\n",
    "    Parameters: df - pandas dataframe\n",
    "                col_name - name of column in df that contains the text to be processed.\n",
    "    -------------------\n",
    "    Returns: X - a list of documents\n",
    "             y - a pandas series of corresponding labels\n",
    "    '''\n",
    "    # create a corpus\n",
    "    print('------------------')\n",
    "    print('Creating corpus...')\n",
    "    documents = list(df[corpus_col_name])\n",
    "\n",
    "    # remove numbers\n",
    "    documents = list(map(lambda x: ' '.join(re.split('[,_\\d]+', x)), documents))\n",
    "    \n",
    "    # clip the intro of each bill\n",
    "    documents = list(map(lambda x: x[(x.index('Office]') + 8):], documents))\n",
    "\n",
    "    # tokenize the corpus\n",
    "    print('------------------')\n",
    "    print('Tokenizing...')\n",
    "    corpus = [word_tokenize(content.lower()) for content in documents]\n",
    "\n",
    "    # strip out the stop words from each \n",
    "    print('------------------')\n",
    "    print('Stripping out stop words, punctuation, and numbers...')\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.extend(['mr', 'ms', 'mrs', 'said', 'year', 'would', 'could', 'also', 'shall', '_______________________________________________________________________'])\n",
    "    # print(stop_words)\n",
    "    corpus = [[token for token in doc if token not in stop_words] for doc in corpus]\n",
    "    # corpus[0]\n",
    "\n",
    "    # strip out the punctuation\n",
    "    punc = set(string.punctuation)\n",
    "    # print(punc)\n",
    "    corpus = [[token for token in doc if token not in punc] for doc in corpus]\n",
    "    # corpus[0]\n",
    "\n",
    "    # strip out the punctuation\n",
    "    string.digits\n",
    "\n",
    "\n",
    "    # lemmatize (and maybe stem?)\n",
    "    print('------------------')\n",
    "    print('Lemmatizing...')\n",
    "    lemmer = WordNetLemmatizer()\n",
    "    corpus = [[lemmer.lemmatize(word) for word in doc] for doc in corpus]\n",
    "    # corpus[0]\n",
    "\n",
    "    # build a vocabulary\n",
    "    print('------------------')\n",
    "    print('Creating a vocabulary...')\n",
    "    vocab_set = set()\n",
    "    [[vocab_set.add(token) for token in tokens] for tokens in corpus]\n",
    "    vocab = list(vocab_set)\n",
    "    # vocab[100000:100020]\n",
    "\n",
    "    # # for later model...\n",
    "    # # examine n-grams...\n",
    "    # # bigrams (two words side-by-side)\n",
    "    # print('------------------')\n",
    "    # print('Creating lists of bigrams, trigrams, skipgrams, etc...')\n",
    "    # bigrams = [list(ngrams(sequence = doc, n = 2)) for doc in corpus]\n",
    "    # trigrams = [list(ngrams(sequence = doc, n = 3)) for doc in corpus]\n",
    "    # #... more?\n",
    "\n",
    "    # # skipgrams (n-grams that skip k words)\n",
    "    # skipgrams = [list(skipgrams(sequence = doc, n = 2, k = 1)) for doc in corpus]\n",
    "\n",
    "\n",
    "    # rejoin each doc in corpus so each doc is a single string\n",
    "    corpus = [' '.join(tokens) for tokens in corpus]\n",
    "\n",
    "    print('------------------')\n",
    "    print('NLP preprocessing complete ...')\n",
    "\n",
    "    X = corpus\n",
    "    y = df[labels_col_name].astype('int')\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "Creating column 'labels'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "------------------\n",
      "Data is from the 110th Congress (2007) to present\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "from my_tools import *\n",
    "data = get_bill_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'bill_status', 'body', 'committee', 'congress_id', 'cosponsors',\n",
       "       'cosponsors_url', 'desc', 'intro_date', 'leg_id', 'leg_type', 'leg_url',\n",
       "       'num_of_cosponsors', 'sponsor', 'sponsor_district', 'sponsor_party',\n",
       "       'sponsor_state', 'labels'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50039, 18)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>bill_status</th>\n",
       "      <th>body</th>\n",
       "      <th>committee</th>\n",
       "      <th>congress_id</th>\n",
       "      <th>cosponsors</th>\n",
       "      <th>cosponsors_url</th>\n",
       "      <th>desc</th>\n",
       "      <th>intro_date</th>\n",
       "      <th>leg_id</th>\n",
       "      <th>leg_type</th>\n",
       "      <th>leg_url</th>\n",
       "      <th>num_of_cosponsors</th>\n",
       "      <th>sponsor</th>\n",
       "      <th>sponsor_district</th>\n",
       "      <th>sponsor_party</th>\n",
       "      <th>sponsor_state</th>\n",
       "      <th>labels</th>\n",
       "      <th>bill_char_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5c11d642cd68d16918e58ec1</td>\n",
       "      <td>Became Law</td>\n",
       "      <td>[Congressional Bills 115th Congress] [From the...</td>\n",
       "      <td>House - Financial Services</td>\n",
       "      <td>115th</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>To extend the National Flood Insurance Program...</td>\n",
       "      <td>11/29/2018</td>\n",
       "      <td>H R 7187</td>\n",
       "      <td>LAW</td>\n",
       "      <td>https://www.congress.gov/bill/115th-congress/h...</td>\n",
       "      <td>0</td>\n",
       "      <td>Rep. MacArthur, Thomas</td>\n",
       "      <td>3</td>\n",
       "      <td>NJ</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>5c11d643cd68d16918e58fe3</td>\n",
       "      <td>Became Law</td>\n",
       "      <td>[Congressional Bills 115th Congress] [From the...</td>\n",
       "      <td>House - Transportation and Infrastructure, Way...</td>\n",
       "      <td>115th</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Airport and Airway Extension Act of 2018, Part II</td>\n",
       "      <td>09/26/2018</td>\n",
       "      <td>H R 6897</td>\n",
       "      <td>LAW</td>\n",
       "      <td>https://www.congress.gov/bill/115th-congress/h...</td>\n",
       "      <td>0</td>\n",
       "      <td>Rep. Shuster, Bill</td>\n",
       "      <td>9</td>\n",
       "      <td>PA</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>3585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>5c11d643cd68d16918e58fe4</td>\n",
       "      <td>Became Law</td>\n",
       "      <td>[Congressional Bills 115th Congress] [From the...</td>\n",
       "      <td>House - Judiciary | Senate - Judiciary</td>\n",
       "      <td>115th</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.congress.gov/bill/115th-congress/h...</td>\n",
       "      <td>United States Parole Commission Extension Act ...</td>\n",
       "      <td>09/26/2018</td>\n",
       "      <td>H R 6896</td>\n",
       "      <td>LAW</td>\n",
       "      <td>https://www.congress.gov/bill/115th-congress/h...</td>\n",
       "      <td>1</td>\n",
       "      <td>Rep. Sensenbrenner, F. James, Jr.</td>\n",
       "      <td>5</td>\n",
       "      <td>WI</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>8388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>5c11d643cd68d16918e58ffe</td>\n",
       "      <td>Became Law</td>\n",
       "      <td>[115th Congress Public Law 277] [From the U.S....</td>\n",
       "      <td>House - Oversight and Government Reform, Finan...</td>\n",
       "      <td>115th</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>To rename the Stop Trading on Congressional Kn...</td>\n",
       "      <td>09/25/2018</td>\n",
       "      <td>H R 6870</td>\n",
       "      <td>LAW</td>\n",
       "      <td>https://www.congress.gov/bill/115th-congress/h...</td>\n",
       "      <td>0</td>\n",
       "      <td>Rep. Tonko, Paul</td>\n",
       "      <td>20</td>\n",
       "      <td>NY</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>1209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>5c11d643cd68d16918e5906e</td>\n",
       "      <td>Became Law</td>\n",
       "      <td>[Congressional Bills 115th Congress] [From the...</td>\n",
       "      <td>House - Judiciary</td>\n",
       "      <td>115th</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.congress.gov/bill/115th-congress/h...</td>\n",
       "      <td>SUCCESS Act</td>\n",
       "      <td>09/10/2018</td>\n",
       "      <td>H R 6758</td>\n",
       "      <td>LAW</td>\n",
       "      <td>https://www.congress.gov/bill/115th-congress/h...</td>\n",
       "      <td>10</td>\n",
       "      <td>Rep. Chabot, Steve</td>\n",
       "      <td>1</td>\n",
       "      <td>OH</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>3924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          _id bill_status  \\\n",
       "24   5c11d642cd68d16918e58ec1  Became Law   \n",
       "314  5c11d643cd68d16918e58fe3  Became Law   \n",
       "315  5c11d643cd68d16918e58fe4  Became Law   \n",
       "341  5c11d643cd68d16918e58ffe  Became Law   \n",
       "453  5c11d643cd68d16918e5906e  Became Law   \n",
       "\n",
       "                                                  body  \\\n",
       "24   [Congressional Bills 115th Congress] [From the...   \n",
       "314  [Congressional Bills 115th Congress] [From the...   \n",
       "315  [Congressional Bills 115th Congress] [From the...   \n",
       "341  [115th Congress Public Law 277] [From the U.S....   \n",
       "453  [Congressional Bills 115th Congress] [From the...   \n",
       "\n",
       "                                             committee congress_id cosponsors  \\\n",
       "24                          House - Financial Services       115th       None   \n",
       "314  House - Transportation and Infrastructure, Way...       115th       None   \n",
       "315             House - Judiciary | Senate - Judiciary       115th       None   \n",
       "341  House - Oversight and Government Reform, Finan...       115th       None   \n",
       "453                                  House - Judiciary       115th       None   \n",
       "\n",
       "                                        cosponsors_url  \\\n",
       "24                                                None   \n",
       "314                                               None   \n",
       "315  https://www.congress.gov/bill/115th-congress/h...   \n",
       "341                                               None   \n",
       "453  https://www.congress.gov/bill/115th-congress/h...   \n",
       "\n",
       "                                                  desc  intro_date    leg_id  \\\n",
       "24   To extend the National Flood Insurance Program...  11/29/2018  H R 7187   \n",
       "314  Airport and Airway Extension Act of 2018, Part II  09/26/2018  H R 6897   \n",
       "315  United States Parole Commission Extension Act ...  09/26/2018  H R 6896   \n",
       "341  To rename the Stop Trading on Congressional Kn...  09/25/2018  H R 6870   \n",
       "453                                        SUCCESS Act  09/10/2018  H R 6758   \n",
       "\n",
       "    leg_type                                            leg_url  \\\n",
       "24       LAW  https://www.congress.gov/bill/115th-congress/h...   \n",
       "314      LAW  https://www.congress.gov/bill/115th-congress/h...   \n",
       "315      LAW  https://www.congress.gov/bill/115th-congress/h...   \n",
       "341      LAW  https://www.congress.gov/bill/115th-congress/h...   \n",
       "453      LAW  https://www.congress.gov/bill/115th-congress/h...   \n",
       "\n",
       "    num_of_cosponsors                            sponsor sponsor_district  \\\n",
       "24                  0             Rep. MacArthur, Thomas                3   \n",
       "314                 0                 Rep. Shuster, Bill                9   \n",
       "315                 1  Rep. Sensenbrenner, F. James, Jr.                5   \n",
       "341                 0                   Rep. Tonko, Paul               20   \n",
       "453                10                 Rep. Chabot, Steve                1   \n",
       "\n",
       "    sponsor_party sponsor_state labels  bill_char_counts  \n",
       "24             NJ             R      1              1115  \n",
       "314            PA             R      1              3585  \n",
       "315            WI             R      1              8388  \n",
       "341            NY             D      1              1209  \n",
       "453            OH             R      1              3924  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_lengths = list(map(lambda x: len(x), data['body']))\n",
    "data['bill_char_counts'] = bill_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "Creating corpus...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50039"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a corpus\n",
    "print('------------------')\n",
    "print('Creating corpus...')\n",
    "documents = list(data['body'])\n",
    "\n",
    "# remove numbers\n",
    "documents = list(map(lambda x: ' '.join(re.split('[,_\\d]+', x)), documents))\n",
    "\n",
    "len(documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
