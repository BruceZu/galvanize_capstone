{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tablereader_js.py\n",
    "from pymongo import MongoClient\n",
    "import pprint \n",
    "import pandas as pd \n",
    "import copy\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "from time import sleep\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# create function get_page_data(site_url)\n",
    "def page_to_mongo(site_url, collection_name):\n",
    "    # send GET request using selenium (sites in javascript) and check status\n",
    "    option = webdriver.ChromeOptions()\n",
    "    option.add_argument(' - incognito')\n",
    "\n",
    "    browser = webdriver.Chrome(executable_path='/usr/local/bin/chromedriver', chrome_options=option)\n",
    "\n",
    "    req = requests.get(site_url)\n",
    "    print('_______________')\n",
    "    print('_______________')\n",
    "    print('Request Status Code: {}'.format(req.status_code))\n",
    "    if req.status_code == 200:\n",
    "        # add page html to mongo\n",
    "        collection_name.insert_one('lxml': req.content)\n",
    "\n",
    "    # render in browser and parse the html with BeautifulSoup\n",
    "    browser.get(site_url)\n",
    "    soup = bs(browser.page_source, 'lxml')\n",
    "    print('--------------')\n",
    "    print(site_url)\n",
    "    print(soup.title)\n",
    "    # print(soup.prettify())\n",
    "\n",
    "    # table of bills are in ol class\n",
    "    # navigate to find bill info\n",
    "    div = soup.find('div', {'class':'search-column-main'})\n",
    "    table = div.find('ol')\n",
    "    # print(table.prettify())\n",
    "\n",
    "    # iterate though each li class expanded to get rows\n",
    "    rows = table.find_all('li', {'class':'expanded'})\n",
    "#     print(rows[0].prettify())\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "    else: \n",
    "        print('!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        print('!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        print('failed to get {}'.format(site_url))\n",
    "        \n",
    "\n",
    "# function to add items to mongo\n",
    "def add_to_mongo(rows):\n",
    "    \n",
    "\n",
    "\n",
    "    # store each row as key-value pair in a dictionary\n",
    "    empty_row = {'bill_id': None, \n",
    "                'bill_url': None, \n",
    "                'congress_id': None,\n",
    "                'desc': None,\n",
    "                'sponsor': None, \n",
    "    #             'cosponsors': None,  #requires navigation to another url and extracting names from table\n",
    "                'committee': None, \n",
    "                'bill_status': None,\n",
    "                'body': None   #requires navigation to another url\n",
    "                }\n",
    "\n",
    "\n",
    "    # all_rows = []\n",
    "\n",
    "    # iterate through each of the 'rows' to fill in the 'columns'\n",
    "    for row in rows:\n",
    "        new_row = copy.copy(empty_row)\n",
    "\n",
    "        columns = row.find_all('a')\n",
    "        new_row['bill_id'] = columns[0].text.strip()\n",
    "        new_row['bill_url'] = columns[0]['href'].strip()\n",
    "        new_row['sponsor'] = columns[1].text.strip()\n",
    "\n",
    "        columns = row.find_all('span')\n",
    "        new_row['congress_id'] = columns[1].text.strip().split()[2]\n",
    "        new_row['desc'] = columns[2].text\n",
    "        new_row['committee'] = columns[4].text.strip()[12:]\n",
    "\n",
    "        columns = row.find_all('p')\n",
    "        new_row['bill_status'] = columns[0].text.strip()[25:]\n",
    "\n",
    "    #     all_rows.append(new_row)\n",
    "    \n",
    "    #     store info in mongo\n",
    "        pages.insert_one(new_row)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # initialize mongo driver to add items as we iterate through them\n",
    "    client = MongoClient('mongodb://localhost:27017/')\n",
    "    db = client.bills\n",
    "    pages = db.pages\n",
    "\n",
    "    # the 101st Congress (1989 - 1990) starts on pg 1011 for pageSize=250\n",
    "    site_url_root = 'https://www.congress.gov/search?q={%22source%22:%22legislation%22}&pageSize=250'\n",
    "    for i in range(1, 1011):\n",
    "        site_url = site_url_root + '&page={}'.format(i)\n",
    "#         print(site_url)\n",
    "        sleep(20)\n",
    "        rows = page_to_mongo(site_url, pages)\n",
    "#         add_to_mongo(rows)\n",
    "\n",
    "    # all_rows[-5:]\n",
    "\n",
    "    print('Count of lines loaded: {}'.format(pages.find().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
